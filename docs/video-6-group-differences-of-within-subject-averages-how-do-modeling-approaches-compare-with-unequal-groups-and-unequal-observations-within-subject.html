<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Video 6: Group differences of within-subject averages: How do modeling approaches compare with unequal groups and unequal observations within-subject? | Tutorial from mixed models YouTube series</title>
  <meta name="description" content="I’ll write a description here later" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Video 6: Group differences of within-subject averages: How do modeling approaches compare with unequal groups and unequal observations within-subject? | Tutorial from mixed models YouTube series" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="I’ll write a description here later" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Video 6: Group differences of within-subject averages: How do modeling approaches compare with unequal groups and unequal observations within-subject? | Tutorial from mixed models YouTube series" />
  
  <meta name="twitter:description" content="I’ll write a description here later" />
  

<meta name="author" content="Jeanette Mumford" />


<meta name="date" content="2020-01-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mumfordbrainstats Mixed Models tutorials</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><i class="fa fa-check"></i>Video 3: Relating two-stage random effects to simulated data and model output</a><ul>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#introduction-1"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#data-simulation"><i class="fa fa-check"></i>Data simulation</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#generate-and-plot-data"><i class="fa fa-check"></i>Generate and plot data</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#run-model-and-compare-to-simulation-settings"><i class="fa fa-check"></i>Run model and compare to simulation settings</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#omitting-random-effects-can-inflate-type-i-error"><i class="fa fa-check"></i>Omitting random effects can inflate Type I error</a></li>
<li class="chapter" data-level="" data-path="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html"><a href="video-3-relating-two-stage-random-effects-to-simulated-data-and-model-output.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><i class="fa fa-check"></i>Video 4: The Two-stage temptation: Why don’t we just use the summary statistics approach??</a><ul>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html#introduction-2"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html#simulated-data"><i class="fa fa-check"></i>Simulated data</a></li>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html#stage-summary-statistics-approach-compared-to-predicted-subject-effects-from-lmer"><i class="fa fa-check"></i>2-stage summary statistics approach compared to predicted subject effects from lmer</a></li>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html#ols-versus-conditional-modes"><i class="fa fa-check"></i>OLS versus conditional modes</a></li>
<li class="chapter" data-level="" data-path="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html"><a href="video-4-the-two-stage-temptation-why-dont-we-just-use-the-summary-statistics-approach.html#summary-and-whats-next"><i class="fa fa-check"></i>Summary and what’s next</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"><a href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"><i class="fa fa-check"></i>Video 5: Relationship between OLS estimates and conditional modes: within-subject means</a><ul>
<li class="chapter" data-level="" data-path="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"><a href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html#introduction-3"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"><a href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html#the-equation-for-shrinkage"><i class="fa fa-check"></i>The equation for shrinkage</a><ul>
<li class="chapter" data-level="" data-path="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html"><a href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html#verifying-coef.lmer-is-following-the-equation"><i class="fa fa-check"></i>Verifying coef.lmer is following the equation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><i class="fa fa-check"></i>Video 6: Group differences of within-subject averages: How do modeling approaches compare with unequal groups and unequal observations within-subject?</a><ul>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html#introduction-4"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html#functions-for-data-simulation-and-analyses"><i class="fa fa-check"></i>Functions for data simulation and analyses</a></li>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html#type-i-error"><i class="fa fa-check"></i>Type I error</a></li>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html#power"><i class="fa fa-check"></i>Power</a></li>
<li class="chapter" data-level="" data-path="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html"><a href="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tutorial from mixed models YouTube series</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="video-6-group-differences-of-within-subject-averages-how-do-modeling-approaches-compare-with-unequal-groups-and-unequal-observations-within-subject" class="section level1">
<h1>Video 6: Group differences of within-subject averages: How do modeling approaches compare with unequal groups and unequal observations within-subject?</h1>
<div id="introduction-4" class="section level2">
<h2>Introduction</h2>
<p>Previous lessons focused on the regularization built into a mixed model. When I explained this to a colleague of mine, she asked how the regularization would impact her results, since she’s studying a patient group that tends to be much smaller than her control group and it tends to be the case that she also has less data per subject in her patient group. Will the regularization of the mixed model hurt her power to detect group differences? In this lesson I focus on different approaches to modeling the data (mixed models, 2SSS and two pseudo 2SSS approaches) to investigate type I error and power when data are both balanced and unbalanced within-group and within-subject. Additionally, these simulations will address my previous comments about why the conditional modes are not the perfect way of viewing regularization.</p>
<p>the focus in on how the regularization, that is part of a mixed model, impacts results and the simulations here will also clarify why I have been saying the conditional modes aren’t the perfect way of viewing the regularization.</p>
<p>There are four modeling approaches, total. First, the standard mixed model, with the group variable as a fixed effect and a random intercept. Second, the 2SSS using OLS at both stages. The last two models are similar to 2SSS, but for the first stage use conditional mode-based subject estimates from each of two different mixed models: one that models group as a fixed effect and one that does not. Although it is easy to argue that neither of these pseudo 2SSS models makes any sense, I can assure you that I have definitely seen this done in practice and therefore wanted to discuss it here. As we will see, neither of these approaches is a good idea. Surely, the second pseudo 2SSS model is most nonsensical since the model from which the conditional modes are extracted actually contains the inference of interest (group difference). Why do that extra work?</p>
<p>First think through how each of these approaches might behave. The 2SSS approach will not deal with the differing number of time points, so I would expect to see some issues there due to the variance differences between groups. For the mixed model there shouldn’t be an issue. Sure, there could be some regularization, but since each group’s mean is modeled, the bias would be toward the group means and not the overall mean. The conditional modes from the model with an intercept only will definitely yield some bias that could hide or emphasize the difference between groups. Also, the extra variability introduced by using these predicted values will likely lead to an underestimate of the variance. The 2SSS with conditional modes from the two group mixed model should have less bias, but the variance estimates will still be incorrect.</p>
<p>A very important consideration when you are interested in power, is you must first verify the type I error is controlled. That is how these simulations are set up. For the type I error investigation, the group means are set equal to each other. Then power is investigated in all scenarios, but it is very important to ignore the power estimates for the models that were not found to have controlled type I error. For that reason I have only put “ghosts” of the power estimates for those models in the plots. Bias is also important. Obviously the mixed model’s conditional modes will be biased on purpose, but we don’t want our final estimates to also be biased, because that can be misleading. You should suspect the pseudo 2SSS using conditional modes from the mixed model without modeling group will have a biased group difference estimate.</p>
<p>In the following the function for data simulation is constructed first, followed by a function that runs the analyses on numerous data sets so type I error and power can be calculated. After that I run 4 simulations for different study designs investigating type I error. Last power is estimated across the four designs. You are highly encouraged to try out your own designs. I have made the functions fairly flexible so you could do so. Do keep in mind that quite a few simulations are required and so it will take some time for them to complete.</p>
</div>
<div id="functions-for-data-simulation-and-analyses" class="section level2">
<h2>Functions for data simulation and analyses</h2>
<p>This first function simulates data for two groups. The code should seem very familiar, since it is based on the previous lessons that simulated data using the 2 stage approach. The one difference is there is a group variable here, while the previous simulations were for a single group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)
<span class="kw">library</span>(lmerTest)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(knitr)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(ggpubr)

make.data.grps =<span class="st"> </span>function(win, btwn, n.win.sub, group.vec, grp1.mean, grp2.mean){
  <span class="co">#win:  A vector of the within-subject sd of length nsub</span>
  <span class="co">#btwn: Scalar, the between-subject sd</span>
  <span class="co"># group.vec: 1&#39;s and 0&#39;s indicating group membership.  Length nsub.</span>
  <span class="co"># grp1.mean:  Mean for group 1 (group.vec=0)</span>
  <span class="co"># grp2.mean:  Mean for group 2 (group.vec=1)</span>
  
  nsub =<span class="st"> </span><span class="kw">length</span>(group.vec)
  <span class="co"># Simulate means for each subject</span>
  mns.sub =<span class="st"> </span>grp1.mean*group.vec +<span class="st"> </span>(<span class="dv">1</span>-group.vec)*grp2.mean +<span class="st">  </span><span class="kw">rnorm</span>(nsub, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> btwn)
  <span class="co"># Simulate data within-subject</span>
  y =<span class="kw">c</span>()
  id =<span class="st"> </span><span class="kw">c</span>()
  grp.all =<span class="st"> </span><span class="kw">c</span>()
  for (i in <span class="dv">1</span>:nsub){
    y.loop =<span class="st"> </span><span class="kw">rnorm</span>(n.win.sub[i], 
                   <span class="dt">mean =</span> mns.sub[i], <span class="dt">sd =</span> win[i])
    y =<span class="st"> </span><span class="kw">c</span>(y, y.loop)
    id =<span class="st"> </span><span class="kw">c</span>(id, <span class="kw">rep</span>(i, n.win.sub[i]))
   grp.all =<span class="st"> </span><span class="kw">c</span>(grp.all, <span class="kw">rep</span>(group.vec[i], n.win.sub[i]))
  }
  id =<span class="st"> </span><span class="kw">as.factor</span>(id)
  dat.mod =<span class="st"> </span><span class="kw">data.frame</span>(id, y, grp.all)
  <span class="kw">return</span>(dat.mod)
}</code></pre></div>
<p>This function is created to run the simulation and organize the output. We will investigate the mean estimates for each group, the standard error of the difference in means according to each model, and the p-values, which will be used to either calculate power or type I error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">run.sim =<span class="st"> </span>function(nsim, win, n.win.sub, btwn,  group.vec, grp1.mean, grp2.mean, rand.ord.nsub){
  <span class="co">#nsim:  Number of simulations</span>
  <span class="co">#win: within-subject variances.  Vector of length nsub</span>
  <span class="co">#n.win.sub:  Number of measures within-subject.  Vector of length nsub</span>
  <span class="co">#btwn:  between-subject variance</span>
  <span class="co">#group.vec:  1/0 vector indicating groups</span>
  <span class="co">#grp1.mean, grp2.mean:  Group means</span>
  <span class="co">#rand.ord.nsub:  Randomly order subjects (mixes up n.win.sub so random subjects have smaller n)</span>
 
  g1.mean.lmer =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g2.mean.lmer =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g1.mean.2sss =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g2.mean.2sss =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g1.mean.2sss.cond.mode.2grp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g2.mean.2sss.cond.mode.2grp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g1.mean.2sss.cond.mode.nogrp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  g2.mean.2sss.cond.mode.nogrp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  
  diff.se.lmer =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  diff.se.2sss =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  diff.se.2sss.cond.mode.2grp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  diff.se.2sss.cond.mode.nogrp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  
  p.lmer =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  p.2sss =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  p.2sss.cond.mode.2grp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  p.2sss.cond.mode.nogrp =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)
  
  for (i in <span class="dv">1</span>:nsim) {
     <span class="co"># This is used when I want to randomly </span>
     <span class="co">#  select who has less data</span>
    nsub =<span class="st"> </span><span class="kw">length</span>(group.vec)
    if (rand.ord.nsub ==<span class="st"> &#39;yes&#39;</span>){
      n.win.sub =<span class="st"> </span><span class="kw">sample</span>(n.win.sub)
    }
  
    <span class="co"># Generate the data</span>
    dat.mod =<span class="st"> </span><span class="kw">make.data.grps</span>(win, btwn, n.win.sub,
                             group.vec, grp1.mean,
                             grp2.mean)
  
    <span class="co"># Run the 4 models</span>
    <span class="co"># mixed model</span>
    mod.lmer =<span class="st"> </span><span class="kw">lmer</span>(y ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>grp.all +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>id), dat.mod)

    <span class="co"># 2SSS OLS</span>
    <span class="co"># trick for getting OLS means for each subject</span>
    ols.stage1 =<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>id -<span class="dv">1</span>, dat.mod)$coeff
    twosss =<span class="st"> </span><span class="kw">lm</span>(ols.stage1 ~<span class="st"> </span>group.vec)
    
    <span class="co"># 2SSS using cond modes from model including group</span>
    <span class="co"># pull out conditional modes</span>
    cond.modes.2grp.mod =<span class="st"> </span><span class="kw">coef</span>(mod.lmer)$id[, <span class="dv">1</span>]+
<span class="st">                          </span><span class="kw">coef</span>(mod.lmer)$id[, <span class="dv">2</span>]*group.vec
    twosss.cond.mode.2grp =<span class="st"> </span><span class="kw">lm</span>(cond.modes.2grp.mod ~
<span class="st">                                 </span>group.vec)
    <span class="co">#2SSS using cond modes from model without group  </span>
    mod.lmer.nogroup =<span class="st"> </span><span class="kw">lmer</span>(y ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>(<span class="dv">1</span> |<span class="st"> </span>id), dat.mod)
    cond.modes.nogroup.mod =<span class="st"> </span><span class="kw">coef</span>(mod.lmer.nogroup)$id[, <span class="dv">1</span>]
    twosss.cond.mode.nogrp =<span class="st"> </span><span class="kw">lm</span>(cond.modes.nogroup.mod ~
<span class="st">                                  </span>group.vec)
    
    g1.mean.lmer[i] =<span class="st"> </span><span class="kw">sum</span>(<span class="kw">fixef</span>(mod.lmer))
    g2.mean.lmer[i] =<span class="st"> </span><span class="kw">fixef</span>(mod.lmer)[<span class="dv">1</span>]
    g1.mean.2sss[i] =<span class="st"> </span><span class="kw">sum</span>(<span class="kw">coef</span>(twosss))
    g2.mean.2sss[i] =<span class="st"> </span><span class="kw">coef</span>(twosss)[<span class="dv">1</span>]
    g1.mean.2sss.cond.mode.2grp[i] =<span class="st"> </span><span class="kw">sum</span>(<span class="kw">coef</span>(twosss.cond.mode.2grp))
    g2.mean.2sss.cond.mode.2grp[i] =<span class="st"> </span><span class="kw">coef</span>(twosss.cond.mode.2grp)[<span class="dv">1</span>]
    g1.mean.2sss.cond.mode.nogrp[i] =<span class="st"> </span><span class="kw">sum</span>(<span class="kw">coef</span>(twosss.cond.mode.nogrp))
    g2.mean.2sss.cond.mode.nogrp[i] =<span class="st"> </span><span class="kw">coef</span>(twosss.cond.mode.nogrp)[<span class="dv">1</span>]
  
    diff.se.lmer[i] =<span class="st"> </span><span class="kw">summary</span>(mod.lmer)$coeff[<span class="dv">2</span>,<span class="dv">2</span>]
    diff.se.2sss[i] =<span class="st"> </span><span class="kw">summary</span>(twosss)$coeff[<span class="dv">2</span>,<span class="dv">2</span>]
    diff.se.2sss.cond.mode.2grp[i] =<span class="st"> </span><span class="kw">summary</span>(twosss.cond.mode.2grp)$coeff[<span class="dv">2</span>,<span class="dv">2</span>]
    diff.se.2sss.cond.mode.nogrp[i] =<span class="st"> </span><span class="kw">summary</span>(twosss.cond.mode.nogrp)$coeff[<span class="dv">2</span>,<span class="dv">2</span>]
  
    p.lmer[i] =<span class="st"> </span><span class="kw">summary</span>(mod.lmer)$coeff[<span class="dv">2</span>,<span class="dv">5</span>]
    p.2sss[i] =<span class="st"> </span><span class="kw">summary</span>(twosss)$coeff[<span class="dv">2</span>,<span class="dv">4</span>]
    p.2sss.cond.mode.2grp[i] =<span class="st"> </span><span class="kw">summary</span>(twosss.cond.mode.2grp)$coeff[<span class="dv">2</span>,<span class="dv">4</span>]
    p.2sss.cond.mode.nogrp[i] =<span class="st"> </span><span class="kw">summary</span>(twosss.cond.mode.nogrp)$coeff[<span class="dv">2</span>,<span class="dv">4</span>]
  }
  
  <span class="co"># put it all into a data frame</span>
  out =<span class="st"> </span><span class="kw">data.frame</span>(g1.mean.lmer, g2.mean.lmer, 
                   g1.mean.2sss, g2.mean.2sss,
                   g1.mean.2sss.cond.mode.2grp,   
                   g2.mean.2sss.cond.mode.2grp,
                   g1.mean.2sss.cond.mode.nogrp,
                   g2.mean.2sss.cond.mode.nogrp,
                   diff.se.lmer, diff.se.2sss, diff.se.2sss.cond.mode.2grp, 
                   diff.se.2sss.cond.mode.nogrp, p.lmer,
                   p.2sss, p.2sss.cond.mode.2grp,
                   p.2sss.cond.mode.nogrp)
  <span class="kw">return</span>(out)
}</code></pre></div>
</div>
<div id="type-i-error" class="section level2">
<h2>Type I error</h2>
<p>This first batch of simulations will calculate the type I error. In order to do so, the means for the groups are set to be equal (10). I would recommend at least 1000 simulations if you were to run this on your own. The code allows you to change the within-subject variance across subjects, but all model estimation methods assume a constant within-subject variance, so there wasn’t really a reason to vary that here. Feel free to try it out on your own! I start of with balanced groups where either everybody has 30 observations or one group has 5 subjects with only 5 observations. Then, to mimic the real life data my colleague has where her patient group is much smaller and often have less data, I set the group sizes to 10 and 40 where they either all have 30 observations or half the patients only have 5 observations.</p>
<p>I realize the settings are a bit extreme, BUT if I can break a model in the extreme I will never ever use it on my real data. Why take the risk when I don’t know how “extreme” my real data are. If I can’t break a model in the extreme, then I know I can probably almost always trust that model.</p>
<p>By the way, if you’ve been paying close attention, take a look at the simulation settings and think back to the previous lesson. You will see there are differences in model performance here, but what would likely make them more similar? Hint: You’d need to change one number in the simulations I ran below. Again, aiming for the extreme to see what breaks!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 25 subjects each group, everybody has 30 observations</span>
nsim =<span class="st"> </span><span class="dv">100</span>
win =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">10</span>, <span class="dv">50</span>)
n.win.sub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">30</span>, <span class="dv">50</span>)
btwn =<span class="st"> </span><span class="dv">5</span>
group.vec =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">each =</span> <span class="dv">25</span>)
<span class="co"># Set the means equal, since we&#39;re looking at Type I error</span>
grp1.mean =<span class="st"> </span><span class="dv">10</span>
grp2.mean =<span class="st"> </span><span class="dv">10</span>
rand.ord.nsub =<span class="st"> &#39;no&#39;</span>

out<span class="fl">.25.25</span>.nolow.type1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                          group.vec, grp1.mean, 
                          grp2.mean, rand.ord.nsub)

<span class="co"># Change so 5 in first group have low n</span>
n.win.sub[<span class="dv">1</span>:<span class="dv">5</span>] =<span class="st"> </span><span class="dv">5</span>
out<span class="fl">.25.25</span>.5g1.type1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                        group.vec, grp1.mean, 
                        grp2.mean, rand.ord.nsub)

<span class="co">#imblanaced groups with equal n</span>
n.win.sub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">30</span>, <span class="dv">50</span>)
group.vec =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">40</span>))
out<span class="fl">.10.40</span>.nolow.type1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                          group.vec, grp1.mean, grp2.mean,
                          rand.ord.nsub)

<span class="co"># imbalanced groups with some in small group with low n</span>
n.win.sub[<span class="dv">1</span>:<span class="dv">5</span>] =<span class="st"> </span><span class="dv">5</span>
out<span class="fl">.10.40</span>.5g1.type1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn, 
                        group.vec, grp1.mean, grp2.mean,
                        rand.ord.nsub)</code></pre></div>
<p>The following rearranges the data for plotting. First, the mean estimates (within each group and difference of means) are presented for each combination of data setup and analysis type. The boxplots are constructed from the estimates across the simulations. Look for bias in these estimates. Since the truth is known, I have overlayed lines to indicate the true value. Also, one would typically look to see if the estimates varied differently across the models. They do not in this case. There is a discussion about the plots after they are displayed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># arrange for plotting</span>

cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>,<span class="st">&quot;#999999&quot;</span>)

 dat.all.type1 =<span class="st"> </span><span class="kw">rbind</span>(out<span class="fl">.25.25</span>.nolow.type1,
                       out<span class="fl">.25.25</span>.5g1.type1,
                       out<span class="fl">.10.40</span>.nolow.type1,
                       out<span class="fl">.10.40</span>.5g1.type1)
 
 dat.all.type1$sim.type =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;25.25.nolow&quot;</span>,
                                       <span class="st">&quot;25.25.5g1&quot;</span>,
                                       <span class="st">&quot;10.40.nolow&quot;</span>, 
                                       <span class="st">&quot;10.40.5g1&quot;</span>),
                                 <span class="dt">each =</span>nsim), <span class="dt">levels =</span>
                                 <span class="kw">c</span>(<span class="st">&quot;25.25.nolow&quot;</span>, <span class="st">&quot;25.25.5g1&quot;</span>,
                                 <span class="st">&quot;10.40.nolow&quot;</span>, <span class="st">&quot;10.40.5g1&quot;</span>))
 dat.all.type1$n1 =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">10</span>), <span class="dt">each =</span> nsim)
 dat.all.type1$n2 =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">40</span>), <span class="dt">each =</span> nsim)
 dat.all.type1$lown =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;none&quot;</span>, <span class="st">&quot;5 in g1&quot;</span>, <span class="st">&quot;none&quot;</span>, 
                            <span class="st">&quot;5 in g1&quot;</span>),
                          <span class="dt">each =</span> nsim)
 
 col.g1.mean =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;g1.mean&#39;</span>, <span class="kw">names</span>(dat.all.type1), 
                    <span class="dt">fixed =</span> T)
 dat.all.g1.mean.type1 =<span class="st"> </span>dat.all.type1 %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, 
                          <span class="dt">value=</span><span class="st">&quot;group1mean&quot;</span>, 
                          col.g1.mean) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, 
                            <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;g1.mean.&quot;</span>)
 dat.all.g1.mean.type1$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.g1.mean.type1$model, 
                                <span class="dt">levels =</span> 
                                  <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                   <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                    <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))
 
g1.plot.type1 =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.g1.mean.type1, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type,
                                      <span class="dt">y =</span> group1mean, 
                                      <span class="dt">fill =</span> model)) +
<span class="st">                </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span>
<span class="st">                </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>) +
<span class="st">                </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+
<span class="st">                </span><span class="kw">ggtitle</span>(<span class="st">&quot;Group 1 mean&quot;</span>)

<span class="co"># Repeat for g2</span>
col.g2.mean.type1 =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;g2.mean&#39;</span>, <span class="kw">names</span>(dat.all.type1), <span class="dt">fixed =</span> T)
dat.all.g2.mean.type1 =<span class="st"> </span>dat.all.type1 %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;group2mean&quot;</span>,
                          col.g2.mean.type1) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;g2.mean.&quot;</span>)
dat.all.g2.mean.type1$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.g2.mean.type1$model, 
                                <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>)) 
g2.plot.type1 =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.g2.mean.type1, 
                       <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, <span class="dt">y =</span> group2mean, 
                           <span class="dt">fill =</span> model)) +<span class="st"> </span><span class="kw">geom_boxplot</span>() +
<span class="st">                </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>)+
<span class="st">                </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+
<span class="st">                </span><span class="kw">ggtitle</span>(<span class="st">&quot;Group 2 mean&quot;</span>)
 
<span class="co"># Estimate the differences and then plot the differences</span>
dat.all.diff.type1 =<span class="st"> </span><span class="kw">left_join</span>(dat.all.g1.mean.type1, dat.all.g2.mean.type1)
dat.all.diff.type1$diff =<span class="st"> </span>dat.all.diff.type1$group2mean -
<span class="st">                    </span>dat.all.diff.type1$group1mean
dat.all.diff.type1$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.diff.type1$model, 
                                <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>)) 
diff.plot.type1 =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.diff.type1, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, 
                                                 <span class="dt">y =</span> diff, 
                                                 <span class="dt">fill =</span> model)) +
<span class="st">                   </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span>
<span class="st">                   </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>)+
<span class="st">                   </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+
<span class="st">                   </span><span class="kw">ggtitle</span>(<span class="st">&quot;Difference&quot;</span>)

<span class="co"># plot all 3 together</span>
<span class="kw">ggarrange</span>(g1.plot.type1, g2.plot.type1, diff.plot.type1, <span class="dt">common.legend =</span> <span class="ot">TRUE</span>,
          <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">legend =</span> <span class="st">&quot;right&quot;</span>)</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>In the above plots, there is no bias present. This doesn’t mean all methods are generally unbiased, it simply means when both group means are 0 there isn’t bias. Think about how the regularization works in the mixed model and ask yourself whether it makes sense that there isn’t bias here, even when some subjects have much less data. Do you predict there will be bias when the group means are different from each other?</p>
<p>Next the standard error of the group differences will be displayed. Generally we want our standard errors to be small BUT that’s only helpful if our resulting inferences are valid (type I error is controlled). The setup is similar to the last plots.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Look at the standard errors</span>
col.se.type1 =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;diff.se&#39;</span>, <span class="kw">names</span>(dat.all.type1), <span class="dt">fixed =</span> T)
dat.all.se.type1 =<span class="st"> </span>dat.all.type1 %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;se&quot;</span>, col.se.type1) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;diff.se.&quot;</span>)
dat.all.se.type1$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.se.type1$model, 
                          <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))
 
<span class="kw">ggplot</span>(dat.all.se.type1, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, <span class="dt">y =</span> se, <span class="dt">fill =</span> model)) +
<span class="st">       </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>It is tempting to get excited about the pseudo 2SSS approaches that use conditional modes based on these standard error distributions BUT remember, we still haven’t looked at type I error and fully investigated bias.</p>
<p>Next up is the type I error investigation, which clearly ends any hope one may have had for the 2SSS model using the conditional mode from the mixed model that had group included as a fixed effect. It doesn’t matter in real life, though, since if one already ran that model they wouldn’t have likely continued to extract conditional modes, etc, because the inference for the group difference was already included in the mixed model and, as the plot shows, the type I errors are preserved in those cases.</p>
<p>There are horizontal lines at 0.05 (solid) and the 95% confidence interval (dashed). We will use type I error beyond the upper confidence bound as the threshold for an invalid test, which will be used to help interpret the power results later.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="co"># Calculate type I error</span>
 col.p =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;p.&#39;</span>, <span class="kw">names</span>(dat.all.type1), <span class="dt">fixed =</span> T)
 dat.all.p.type1 =<span class="st"> </span>dat.all.type1 %&gt;%
<span class="st">              </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;pval&quot;</span>, col.p) %&gt;%
<span class="st">              </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;p.&quot;</span>)
dat.all.p.type1$p.sig =<span class="st"> </span>dat.all.p.type1$pval &lt;=<span class="st"> </span><span class="fl">0.05</span>
type1.mat =<span class="st"> </span><span class="kw">aggregate</span>(p.sig ~<span class="st"> </span>sim.type +<span class="st"> </span>model,
                    <span class="dt">data =</span> dat.all.p.type1, mean)
type1.mat$model =<span class="st"> </span><span class="kw">factor</span>(type1.mat$model, 
                       <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                  <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                  <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))

<span class="co">#bound for type I error (upper bound 95% CI)</span>
bound.up =<span class="st"> </span>.<span class="dv">05</span>+<span class="kw">qnorm</span>(<span class="dv">1</span><span class="fl">-0.05</span>/<span class="dv">2</span>)*<span class="kw">sqrt</span>(<span class="fl">0.05</span>*(<span class="dv">1</span><span class="fl">-0.05</span>)/nsim)
bound.low =<span class="st"> </span>.<span class="dv">05</span>-<span class="kw">qnorm</span>(<span class="dv">1</span><span class="fl">-0.05</span>/<span class="dv">2</span>)*<span class="kw">sqrt</span>(<span class="fl">0.05</span>*(<span class="dv">1</span><span class="fl">-0.05</span>)/nsim)


<span class="kw">ggplot</span>(type1.mat, <span class="kw">aes</span>(<span class="dt">x=</span>sim.type, <span class="dt">y =</span> p.sig, <span class="dt">fill =</span> model)) +<span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">position=</span><span class="kw">position_dodge</span>())+<span class="st"> </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> bound.up,<span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)+<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> bound.low,<span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>)+<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">0.05</span>,<span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>)</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Add column that indicates when p is beyond upper bound</span>
type1.mat$valid =<span class="st"> </span>type1.mat$p.sig&lt;bound.up</code></pre></div>
<p>So far the 2SSS using conditional modes from the mixed model including group is a clear loser. Also, we can see that the OLS-based 2SSS fails when the smaller group has subjects with missing data. This actually makes complete sense since this is exactly what Welch’s t-test is for! Specifically heteroscedasticity, which in this case is driven by the differing within-subject sample sizes. Standard OLS won’t do anything for differing variances, but the mixed model does incorporate this information when the variance differences is driven by different sample sizes.</p>
<p>Last, the 2SSS approach where the conditional mode from the model without group looks somewhat hopeful here, but stay tuned. There’s no avenue for bias to creep in due to the regularization here, since the means for both groups are set to zero!</p>
</div>
<div id="power" class="section level2">
<h2>Power</h2>
<p>The same setup is used below, but the mean for the first group has been increased to 13, so the true difference between groups is 3. I haven’t calculated what the true power should be in this case, so power will just be compared between different models within the same data type, but ignoring any power results for which the type I error was not controlled.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 25 subjects each group, everybody has 30 observations</span>
win =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">10</span>, <span class="dv">50</span>)
n.win.sub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">30</span>, <span class="dv">50</span>)
btwn =<span class="st"> </span><span class="dv">5</span>
group.vec =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">each =</span> <span class="dv">25</span>)
grp1.mean =<span class="st"> </span><span class="dv">13</span>
grp2.mean =<span class="st"> </span><span class="dv">10</span>
rand.ord.nsub =<span class="st"> &#39;no&#39;</span>

out<span class="fl">.25.25</span>.nolow =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                          group.vec, grp1.mean, 
                          grp2.mean, rand.ord.nsub)

<span class="co"># Change so 5 in first group have low n</span>
n.win.sub[<span class="dv">1</span>:<span class="dv">5</span>] =<span class="st"> </span><span class="dv">5</span>
out<span class="fl">.25.25</span>.5g1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                        group.vec, grp1.mean, 
                        grp2.mean, rand.ord.nsub)

<span class="co">#imblanaced groups with equal n</span>
n.win.sub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">30</span>, <span class="dv">50</span>)
group.vec =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">40</span>))
out<span class="fl">.10.40</span>.nolow =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn,
                          group.vec, grp1.mean, grp2.mean,
                          rand.ord.nsub)

<span class="co"># imbalanced groups with some in small group with low n</span>
n.win.sub[<span class="dv">1</span>:<span class="dv">5</span>] =<span class="st"> </span><span class="dv">5</span>
out<span class="fl">.10.40</span>.5g1 =<span class="st"> </span><span class="kw">run.sim</span>(nsim, win, n.win.sub, btwn, 
                        group.vec, grp1.mean, grp2.mean,
                        rand.ord.nsub)</code></pre></div>
<p>Starting again with plots of the within-group means and mean difference. You can definitely see some bias showing. Try and understand where the bias is coming from and why it is in the direction it is. Even though all results are present here, recall we’ve written off the 2SSS using conditional modes from the mixed model that included group. Also, the 2SSS for imbalanced groups where one group has less data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># arrange for plotting</span>

cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>,<span class="st">&quot;#999999&quot;</span>)

 dat.all =<span class="st"> </span><span class="kw">rbind</span>(out<span class="fl">.25.25</span>.nolow, out<span class="fl">.25.25</span>.5g1,
                 out<span class="fl">.10.40</span>.nolow, out<span class="fl">.10.40</span>.5g1)
 
 dat.all$sim.type =<span class="st"> </span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;25.25.nolow&quot;</span>, <span class="st">&quot;25.25.5g1&quot;</span>,
                                 <span class="st">&quot;10.40.nolow&quot;</span>, <span class="st">&quot;10.40.5g1&quot;</span>),
                               <span class="dt">each =</span>nsim), <span class="dt">levels =</span>
                             <span class="kw">c</span>(<span class="st">&quot;25.25.nolow&quot;</span>, <span class="st">&quot;25.25.5g1&quot;</span>,
                               <span class="st">&quot;10.40.nolow&quot;</span>, <span class="st">&quot;10.40.5g1&quot;</span>))
 dat.all$n1 =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">10</span>), <span class="dt">each =</span> nsim)
 dat.all$n2 =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">40</span>), <span class="dt">each =</span> nsim)
 dat.all$lown =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;none&quot;</span>, <span class="st">&quot;5 in g1&quot;</span>, <span class="st">&quot;none&quot;</span>, <span class="st">&quot;5 in g1&quot;</span>),
                    <span class="dt">each =</span> nsim)
 
 
 col.g1.mean =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;g1.mean&#39;</span>, <span class="kw">names</span>(dat.all), <span class="dt">fixed =</span> T)
 dat.all.g1.mean =<span class="st"> </span>dat.all %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, 
                          <span class="dt">value=</span><span class="st">&quot;group1mean&quot;</span>, 
                          col.g1.mean) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, 
                            <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;g1.mean.&quot;</span>)
 dat.all.g1.mean$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.g1.mean$model, 
                                <span class="dt">levels =</span> 
                                  <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                   <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                    <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))
 
g1.plot =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.g1.mean, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type,
                                      <span class="dt">y =</span> group1mean, 
                                      <span class="dt">fill =</span> model)) +
<span class="st">          </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span>
<span class="st">          </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">13</span>, 
                     <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>) +
<span class="st">          </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+
<span class="st">          </span><span class="kw">ggtitle</span>(<span class="st">&quot;Group 1 mean&quot;</span>)

<span class="co"># Repeat for g2</span>
col.g2.mean =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;g2.mean&#39;</span>, <span class="kw">names</span>(dat.all), <span class="dt">fixed =</span> T)
dat.all.g2.mean =<span class="st"> </span>dat.all %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;group2mean&quot;</span>,
                          col.g2.mean) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;g2.mean.&quot;</span>)
dat.all.g2.mean$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.g2.mean$model, 
                                <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>)) 
g2.plot =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.g2.mean, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, <span class="dt">y =</span> group2mean, <span class="dt">fill =</span> model)) +<span class="st"> </span>
<span class="st">        </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span>
<span class="st">        </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>) +<span class="st">      </span>
<span class="st">        </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+<span class="kw">ggtitle</span>(<span class="st">&quot;Group 2 mean&quot;</span>)
 
<span class="co"># Estimate the differences and then plot the differences</span>
dat.all.diff =<span class="st"> </span><span class="kw">left_join</span>(dat.all.g1.mean, dat.all.g2.mean)
dat.all.diff$diff =<span class="st"> </span>dat.all.diff$group2mean -
<span class="st">                    </span>dat.all.diff$group1mean
dat.all.diff$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.diff$model, 
                                <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>)) 
diff.plot =<span class="st"> </span><span class="kw">ggplot</span>(dat.all.diff, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, <span class="dt">y =</span> diff,
                                     <span class="dt">fill =</span> model)) +
<span class="st">            </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> -<span class="dv">3</span>,
                                        <span class="dt">color =</span> <span class="st">&quot;gray26&quot;</span>)+
<span class="st">            </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+
<span class="st">            </span><span class="kw">ggtitle</span>(<span class="st">&quot;Difference&quot;</span>)

<span class="co"># plot all 3 together</span>
<span class="kw">ggarrange</span>(g1.plot, g2.plot, diff.plot, <span class="dt">common.legend =</span> <span class="ot">TRUE</span>,
          <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">legend =</span> <span class="st">&quot;right&quot;</span>)</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>There is always some bias on the 2SSS approach that used conditional modes from the mixed model without a fixed effect for group. It gets worse when group 1 is small and some of those subjects only had 5 observations, because that’s when the regularization will be strongest and the regularization is pulling the estimates toward the overall mean, not the mean of group 1. The bias is not present in the 2SSS model that uses the conditional modes from the mixed model with group because the bias in that case will be toward the group mean instead of the overall mean.</p>
<p>An important point to make here is the bias is in the direction of the null. So, although the standard errors are too small, this is overridden by the bias causing the difference estimate to also be too small.</p>
<p>Moving on to the standard errors, the results are similar to before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Look at the standard errors</span>
col.se =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;diff.se&#39;</span>, <span class="kw">names</span>(dat.all), <span class="dt">fixed =</span> T)
dat.all.se =<span class="st"> </span>dat.all %&gt;%
<span class="st">                   </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;se&quot;</span>, col.se) %&gt;%
<span class="st">                   </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), 
                            <span class="dt">sep =</span> <span class="st">&quot;diff.se.&quot;</span>)
 dat.all.se$model =<span class="st"> </span><span class="kw">factor</span>(dat.all.se$model, 
                          <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                      <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))
 
 <span class="kw">ggplot</span>(dat.all.se, <span class="kw">aes</span>(<span class="dt">x =</span> sim.type, <span class="dt">y =</span> se, <span class="dt">fill =</span> model)) +<span class="st"> </span><span class="kw">geom_boxplot</span>() +<span class="st"> </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Last, but not least, power. I have faded out the bars of the power for the methods that were found to not be valid when type I error was estimated above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="co"># Calculate power</span>
 col.p =<span class="st"> </span><span class="kw">grep</span>(<span class="st">&#39;p.&#39;</span>, <span class="kw">names</span>(dat.all), <span class="dt">fixed =</span> T)
 dat.all.p =<span class="st"> </span>dat.all %&gt;%
<span class="st">              </span><span class="kw">gather</span>(<span class="dt">key=</span><span class="st">&quot;key&quot;</span>, <span class="dt">value=</span><span class="st">&quot;pval&quot;</span>, col.p) %&gt;%
<span class="st">              </span><span class="kw">separate</span>(key, <span class="kw">c</span>(<span class="st">&quot;junk1&quot;</span>, <span class="st">&quot;model&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;p.&quot;</span>)
 dat.all.p$p.sig =<span class="st"> </span>dat.all.p$pval &lt;=<span class="st"> </span><span class="fl">0.05</span>
pow.mat =<span class="st"> </span><span class="kw">aggregate</span>(p.sig ~<span class="st"> </span>sim.type +<span class="st"> </span>model,
                    <span class="dt">data =</span> dat.all.p, mean)
pow.mat$model =<span class="st"> </span><span class="kw">factor</span>(pow.mat$model, 
                       <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;lmer&quot;</span>, <span class="st">&quot;2sss&quot;</span>,
                                  <span class="st">&quot;2sss.cond.mode.nogrp&quot;</span>,
                                  <span class="st">&quot;2sss.cond.mode.2grp&quot;</span>))
<span class="co"># Add in valid test info from type 1 error</span>
valid.info =<span class="st"> </span>type1.mat[,<span class="kw">c</span>(<span class="st">&quot;sim.type&quot;</span>, <span class="st">&quot;model&quot;</span>, <span class="st">&quot;valid&quot;</span>)]
pow.mat =<span class="st"> </span><span class="kw">full_join</span>(pow.mat, valid.info)

<span class="kw">ggplot</span>(pow.mat, <span class="kw">aes</span>(<span class="dt">x=</span>sim.type, <span class="dt">y =</span> p.sig, <span class="dt">fill =</span> model, <span class="dt">alpha =</span> valid)) +<span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">position=</span><span class="kw">position_dodge</span>())+<span class="st"> </span><span class="kw">scale_fill_manual</span>(<span class="dt">values=</span>cbPalette)+<span class="kw">scale_alpha_discrete</span>(<span class="dt">range =</span> <span class="kw">c</span>(<span class="fl">0.2</span>, <span class="dv">1</span>))</code></pre></div>
<p><img src="4_video6_group_comparison_three_models_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Firstly, the star of the show, not surprisingly, is lmer. Not only was type I error always, preserved, but it either ties for highest power or has the highest power. Also, remember it was only 1 simple line of code. The 2SSS almost looks like the winner when the patient group is smaller and some patients have fewer data points, but that test had inflated type I error, so the power cannot be considered. As far as the 2SSS approach using conditional modes from the mixed model without group, it seems like maybe this one is okay but remember that bias! Biased estimates aren’t going to be of much use, so that model cannot be recommended.</p>
</div>
<div id="summary-1" class="section level2">
<h2>Summary</h2>
<p>Overall, when comparing group means the mixed model is the safest bet. The clear loser is the 2SSS using conditional modes from the model with group as a fixed effect. The 2SSS approach might be okay in a pinch if your groups are balanced and data within-subject are balanced, but I will remind you the mixed model was a single line of code. The 2SSS approach with conditional modes extracted from the mixed model without an intercept may yield biased results, due to the regularization, so it should also be avoided.</p>
<p>I would like to circle back to when I used the conditional modes to illustrate the regularization earlier. I kept mentioning that they were not perfect and these simulations show why. The estimates from the 2SSS approach using conditional modes that modeled group were extracted from the exact same model used for the lmer results, yet look how different the performance is! I know it is often the case that these values are plotted in manuscripts to help understand what the individual subjects were doing BUT it is very important when you make plots that they are representative of what the model was actually doing. In this case it can be misleading so I would recommend one be careful if using such plots and make sure the reader understands that the values are simply predictions with high variability and do not perfectly represent how individual subjects behaved in the model. Again, this is because the mixed model isn’t actually using those estimates and those estimates are very noisy predictions. So, they were nice for visualizing how the regularization works, but they are not the same as what is going on inside of the model!</p>
<p>If you haven’t already figured it out, I have set the between-subject variance to be quite small here. If increased, the results will be more similar across modeling approaches. Since we don’t know what our true within- and between-subject variances are, I would never assume the between subject was large enough that I didn’t need to worry when it is often the case that I can simply use the appropriate model.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="video-5-relationship-between-ols-estimates-and-conditional-modes-within-subject-means.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MixedModelsTutorials.pdf", "MixedModelsTutorials.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
