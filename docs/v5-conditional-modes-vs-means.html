<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>V5: Conditional modes vs means | The MumfordBrainStats Mixed Models Series: Companion for the YouTube series</title>
  <meta name="description" content="V5: Conditional modes vs means | The MumfordBrainStats Mixed Models Series: Companion for the YouTube series" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="V5: Conditional modes vs means | The MumfordBrainStats Mixed Models Series: Companion for the YouTube series" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="./images/mixed_model_book_cover.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="V5: Conditional modes vs means | The MumfordBrainStats Mixed Models Series: Companion for the YouTube series" />
  
  
  <meta name="twitter:image" content="./images/mixed_model_book_cover.png" />

<meta name="author" content="Jeanette Mumford" />


<meta name="date" content="2020-01-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="v4-introduction-to-regularization-in-mixed-models.html"/>
<link rel="next" href="v6-model-strategy-comparison-group-differences.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Mumfordbrainstats Mixed Models</a></li>
<li><a href="https://www.youtube.com/watch?v=IGHm1XHFWMc&list=PLB2iAtgpI4YEAUiEQ1ZnfMXY-yewNzn9z">YouTube Mixed Models series playlist</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html"><i class="fa fa-check"></i>V3: Simulation using 2-stage random effects</a>
<ul>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#introduction-1"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#data-simulation"><i class="fa fa-check"></i>Data simulation</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#generate-and-plot-data"><i class="fa fa-check"></i>Generate and plot data</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#run-model-and-compare-to-simulation-settings"><i class="fa fa-check"></i>Run model and compare to simulation settings</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#omitting-random-effects-can-inflate-type-i-error"><i class="fa fa-check"></i>Omitting random effects can inflate Type I error</a></li>
<li class="chapter" data-level="" data-path="v3-simulation-using-2-stage-random-effects.html"><a href="v3-simulation-using-2-stage-random-effects.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html"><i class="fa fa-check"></i>V4: Introduction to regularization in mixed models</a>
<ul>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html#introduction-2"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html#simulated-data"><i class="fa fa-check"></i>Simulated data</a></li>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html#stage-summary-statistics-approach-compared-to-conditional-modes"><i class="fa fa-check"></i>2-stage summary statistics approach compared to conditional modes</a></li>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html#ols-versus-conditional-modes"><i class="fa fa-check"></i>OLS versus conditional modes</a></li>
<li class="chapter" data-level="" data-path="v4-introduction-to-regularization-in-mixed-models.html"><a href="v4-introduction-to-regularization-in-mixed-models.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="v5-conditional-modes-vs-means.html"><a href="v5-conditional-modes-vs-means.html"><i class="fa fa-check"></i>V5: Conditional modes vs means</a>
<ul>
<li class="chapter" data-level="" data-path="v5-conditional-modes-vs-means.html"><a href="v5-conditional-modes-vs-means.html#introduction-3"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="v5-conditional-modes-vs-means.html"><a href="v5-conditional-modes-vs-means.html#the-equation-for-shrinkage"><i class="fa fa-check"></i>The equation for shrinkage</a></li>
<li class="chapter" data-level="" data-path="v5-conditional-modes-vs-means.html"><a href="v5-conditional-modes-vs-means.html#verifying-coef.lmer-is-following-the-equation"><i class="fa fa-check"></i>Verifying coef.lmer is following the equation</a></li>
<li class="chapter" data-level="" data-path="v5-conditional-modes-vs-means.html"><a href="v5-conditional-modes-vs-means.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html"><i class="fa fa-check"></i>V6: Model strategy comparison - group differences</a>
<ul>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#introduction-4"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#modeling-strategies-considered"><i class="fa fa-check"></i>Modeling strategies considered</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#functions-for-data-simulation-and-analyses"><i class="fa fa-check"></i>Functions for data simulation and analyses</a></li>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#type-i-error"><i class="fa fa-check"></i>Type I error</a></li>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#power"><i class="fa fa-check"></i>Power</a></li>
<li class="chapter" data-level="" data-path="v6-model-strategy-comparison-group-differences.html"><a href="v6-model-strategy-comparison-group-differences.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The MumfordBrainStats Mixed Models Series: Companion for the YouTube series</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="v5-conditional-modes-vs-means" class="section level1">
<h1>V5: Conditional modes vs means</h1>
<div id="relationship-between-mixed-model-conditional-modes-aka-blups-and-ols-estimates" class="section level2 unlisted">
<h2>Relationship between mixed model conditional modes (aka BLUPS) and OLS estimates</h2>
</div>
<div id="introduction-3" class="section level2">
<h2>Introduction</h2>
<p>This chapter accompanies the fifth video in the mixed models series, <a href="https://youtu.be/QqEUKlKPos4">“Relationship between mixed model conditional modes (aka BLUPS) and OLS estimates”</a>.
In the last chapter, mixed models were contrasted to using the two-stage summary statistics model (2SSS) focusing on the regularization that is built into mixed models. Specifically, the ordinary least squares (OLS) estimates from stage 1 of 2SSS were compared to the conditional mode-based subject predictions from mixed models to show the regularization of the estimates, within-subject, in the mixed model setting. Although the conditional mode predictions are not perfect, that exploration will be started in the next segment. Here the focus is on the details of the relationship of the OLS estimates and the conditional mode estimates as there is an equation that describes this relationship! Why is this exciting? Because it helps build intuition about when these two approaches will greatly differ. I will be briefly discussing this equation below, but for more technical details see section 8.7 of the <a href="https://www.amazon.com/Applied-Longitudinal-Analysis-Garrett-Fitzmaurice/dp/0470380276">Applied Longitudinal Analysis text by Fitzmaurice and others</a>.</p>
<p>I will stick with the simplified example from last time, where there are multiple measures of reaction time for each subject and the interest is in the mean. Here’s a reminder of how the data were generated (exactly the same code as last time and seed is fixed so same numbers are generated):</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="v5-conditional-modes-vs-means.html#cb15-1"></a><span class="kw">library</span>(lme4)</span>
<span id="cb15-2"><a href="v5-conditional-modes-vs-means.html#cb15-2"></a><span class="kw">library</span>(lmerTest)</span>
<span id="cb15-3"><a href="v5-conditional-modes-vs-means.html#cb15-3"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb15-4"><a href="v5-conditional-modes-vs-means.html#cb15-4"></a><span class="kw">set.seed</span>(<span class="dv">1850</span>)  <span class="co"># This is simply fixing the seed so the code always gives the same result.  </span></span>
<span id="cb15-5"><a href="v5-conditional-modes-vs-means.html#cb15-5"></a><span class="co">#Obviously omit this if you are running new simulations</span></span>
<span id="cb15-6"><a href="v5-conditional-modes-vs-means.html#cb15-6"></a></span>
<span id="cb15-7"><a href="v5-conditional-modes-vs-means.html#cb15-7"></a><span class="co"># Simulate true subject-specific means:</span></span>
<span id="cb15-8"><a href="v5-conditional-modes-vs-means.html#cb15-8"></a>nsub =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb15-9"><a href="v5-conditional-modes-vs-means.html#cb15-9"></a>btwn.sub.sd =<span class="st"> </span><span class="dv">10</span></span>
<span id="cb15-10"><a href="v5-conditional-modes-vs-means.html#cb15-10"></a><span class="co">#within-subject means</span></span>
<span id="cb15-11"><a href="v5-conditional-modes-vs-means.html#cb15-11"></a>win.means =<span class="st"> </span><span class="kw">rnorm</span>(nsub, <span class="dt">mean =</span> <span class="dv">250</span>, <span class="dt">sd =</span> btwn.sub.sd)</span>
<span id="cb15-12"><a href="v5-conditional-modes-vs-means.html#cb15-12"></a></span>
<span id="cb15-13"><a href="v5-conditional-modes-vs-means.html#cb15-13"></a><span class="co"># Simualte data for each subject by wiggling around their means</span></span>
<span id="cb15-14"><a href="v5-conditional-modes-vs-means.html#cb15-14"></a>win.sub.sd =<span class="st"> </span><span class="dv">20</span></span>
<span id="cb15-15"><a href="v5-conditional-modes-vs-means.html#cb15-15"></a><span class="co"># The following indicates how many data per subject, the first 5 only have 5 observations.</span></span>
<span id="cb15-16"><a href="v5-conditional-modes-vs-means.html#cb15-16"></a>n.per.sub =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">50</span>, nsub)</span>
<span id="cb15-17"><a href="v5-conditional-modes-vs-means.html#cb15-17"></a>n.per.sub[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] =<span class="st"> </span><span class="dv">5</span></span>
<span id="cb15-18"><a href="v5-conditional-modes-vs-means.html#cb15-18"></a>rt =<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb15-19"><a href="v5-conditional-modes-vs-means.html#cb15-19"></a>subid =<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb15-20"><a href="v5-conditional-modes-vs-means.html#cb15-20"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsub){</span>
<span id="cb15-21"><a href="v5-conditional-modes-vs-means.html#cb15-21"></a>  rt.loop =<span class="st"> </span><span class="kw">rnorm</span>(n.per.sub[i], win.means[i], <span class="dt">sd =</span> win.sub.sd)</span>
<span id="cb15-22"><a href="v5-conditional-modes-vs-means.html#cb15-22"></a>  rt =<span class="st"> </span><span class="kw">c</span>(rt, rt.loop)</span>
<span id="cb15-23"><a href="v5-conditional-modes-vs-means.html#cb15-23"></a>  subid =<span class="st"> </span><span class="kw">c</span>(subid, <span class="kw">rep</span>(i, n.per.sub[i]))</span>
<span id="cb15-24"><a href="v5-conditional-modes-vs-means.html#cb15-24"></a>}</span>
<span id="cb15-25"><a href="v5-conditional-modes-vs-means.html#cb15-25"></a>dat =<span class="st"> </span><span class="kw">data.frame</span>(subid, rt)</span></code></pre></div>
</div>
<div id="the-equation-for-shrinkage" class="section level2">
<h2>The equation for shrinkage</h2>
<p>As a reminder, the formula for the mixed model is: <span class="math display">\[Y_i = X_i\beta + A_ib_i + \epsilon_i. \]</span> With the data setup for this chapter, <span class="math inline">\(Y_i\)</span> is a vector of reaction times for subject <span class="math inline">\(i\)</span>, <span class="math inline">\(X_i = Z_iA_i\)</span> simplifies to <span class="math inline">\(Z_i\)</span>, since we are only estimating an average over subjects. Since we are also only estimating a within-subject average, <span class="math inline">\(Z_i\)</span> is simply a column of 1s with length <span class="math inline">\(N_i\)</span>, the number of observations for subject <span class="math inline">\(i\)</span>. The random effect, <span class="math inline">\(b_i\)</span>, is of length 1 since only a random intercept in necessary. Specifically, <span class="math inline">\(b_i\sim N(0, G)\)</span>, where <span class="math inline">\(G\)</span> is a scalar, and <span class="math inline">\(\epsilon_i\)</span> describes the within-subject variability, <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2I_{N_i})\)</span>. If needed, review the more detailed explanation of these matrices and vectors from previous lessons.</p>
<p>The following are what we need to focus on and I quickly relate the parameters to the output of the code below, which is repeated code from the last lesson.</p>
<ul>
<li><span class="math inline">\(\hat\beta\)</span>: The fixed effects (group) estimate of the mean from the mixed model. This is the estimated group intercept, 253.88 below.</li>
<li><span class="math inline">\(\hat\beta_i\)</span>: The conditional mode, predicted value for subject <span class="math inline">\(i\)</span> from the mixed model. These values are stored in the mmcm vector created with the coef function below.</li>
<li><span class="math inline">\(\hat\beta_i^{OLS}\)</span>: The OLS-based estimate from stage 1 of 2SSS, <span class="math inline">\(Y_i = Z_i\beta_i^{OLS} + \gamma_i.\)</span> These are stored in the stage1.est vector below.</li>
<li><span class="math inline">\(N_i\)</span>: the number of data points for subject <span class="math inline">\(i\)</span>. For now this is 5 for the first 5 subjects and 50 for the second 5 subjects.</li>
<li><span class="math inline">\(G\)</span> and <span class="math inline">\(\sigma^2\)</span>: Between-subject variance/covariance matrix and within-subject variance. In this case we’ll work with the estimates which are <span class="math inline">\(G=6.309^2\)</span> and <span class="math inline">\(\sigma^2 = 20.577^2\)</span> and stored in vcov.vals. Find them in the mixed model output below.</li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="v5-conditional-modes-vs-means.html#cb16-1"></a><span class="co"># Stage 1</span></span>
<span id="cb16-2"><a href="v5-conditional-modes-vs-means.html#cb16-2"></a>stage1.est =<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsub)</span>
<span id="cb16-3"><a href="v5-conditional-modes-vs-means.html#cb16-3"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsub){</span>
<span id="cb16-4"><a href="v5-conditional-modes-vs-means.html#cb16-4"></a>  <span class="co"># Estimating the mean RT via linear regression</span></span>
<span id="cb16-5"><a href="v5-conditional-modes-vs-means.html#cb16-5"></a>  mod.loop =<span class="st"> </span><span class="kw">lm</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, dat[dat<span class="op">$</span>subid<span class="op">==</span>i,])</span>
<span id="cb16-6"><a href="v5-conditional-modes-vs-means.html#cb16-6"></a>  stage1.est[i] =<span class="st"> </span>mod.loop<span class="op">$</span>coef[<span class="dv">1</span>]</span>
<span id="cb16-7"><a href="v5-conditional-modes-vs-means.html#cb16-7"></a>}</span>
<span id="cb16-8"><a href="v5-conditional-modes-vs-means.html#cb16-8"></a>mod.lmer =<span class="st"> </span><span class="kw">lmer</span>(rt <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>subid), dat)</span>
<span id="cb16-9"><a href="v5-conditional-modes-vs-means.html#cb16-9"></a><span class="kw">summary</span>(mod.lmer)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: rt ~ 1 + (1 | subid)
##    Data: dat
## 
## REML criterion at convergence: 2449.6
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.54753 -0.69671  0.02651  0.72996  2.80661 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  subid    (Intercept)  39.81    6.309  
##  Residual             423.42   20.577  
## Number of obs: 275, groups:  subid, 10
## 
## Fixed effects:
##             Estimate Std. Error      df t value Pr(&gt;|t|)    
## (Intercept)  253.885      2.638   6.206   96.25 4.35e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="v5-conditional-modes-vs-means.html#cb18-1"></a>mmcm =<span class="st"> </span><span class="kw">coef</span>(mod.lmer)<span class="op">$</span>subid[, <span class="dv">1</span>]</span>
<span id="cb18-2"><a href="v5-conditional-modes-vs-means.html#cb18-2"></a>vcov.vals =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">VarCorr</span>(mod.lmer)) <span class="co">#random effects values</span></span>
<span id="cb18-3"><a href="v5-conditional-modes-vs-means.html#cb18-3"></a>beta.hat =<span class="st"> </span><span class="kw">summary</span>(mod.lmer)<span class="op">$</span>coefficients[<span class="dv">1</span>]</span></code></pre></div>
<p>If one is interested in the derivation of the relationship between <span class="math inline">\(\hat\beta_i\)</span> and <span class="math inline">\(\hat\beta_i^{OLS}\)</span>, see section 8.7 of the <a href="https://www.amazon.com/Applied-Longitudinal-Analysis-Garrett-Fitzmaurice/dp/0470380276">Applied Longitudinal Analysis text by Fitzmaurice and others</a>. The end result is: <span class="math display">\[\hat\beta_i = W_i\hat\beta_i^{OLS}+(I_q-W_i)A_i\hat\beta,\]</span>
where <span class="math inline">\(q\)</span> is the dimension of G and <span class="math display">\[W_i= G\{G+\sigma^2(Z_i&#39;Z_i)^{-1}\}^{-1}.\]</span>
Before tackling what <span class="math inline">\(W_i\)</span> is, exactly, focus on the general structure of the relationship assuming <span class="math inline">\(A_i\)</span> is the identity matrix (more on this in a future lesson). If the weight, <span class="math inline">\(W_i\)</span>, is very small, then what counts the most toward the estimate of <span class="math inline">\(\hat\beta_i\)</span> is the fixed effects estimate of <span class="math inline">\(\beta\)</span>. From the last lesson you might suspect that <span class="math inline">\(W_i\)</span> will be small when a subject has less data, since that’s when more regularization was present. On the other hand, if <span class="math inline">\(W_i\)</span> is very large, the conditional mode-based estimate from the mixed model will look very similar to the within-subject estimate from the first stage of 2SSS, which is what we saw for the subjects who had more data in the last lesson.</p>
<p>Let’s test that theory by deriving <span class="math inline">\(W_i\)</span> for our specific model. Recall <span class="math inline">\(Z_i\)</span> is just a column of 1s of length <span class="math inline">\(N_i\)</span>, so <span class="math inline">\((Z_i&#39;Z_i)^{-1} = 1/N_i\)</span> and <span class="math inline">\(G\)</span> is just a scalar (between-subject variance of the mean), so we have: <span class="math display">\[W_i  = \frac{G}{G+\sigma^2/N_i}=\frac{6.31^2}{6.31^2+20.58^2/N_i}.\]</span></p>
<p>Now it is crystal clear that our suspicions from the last lesson are true: for small <span class="math inline">\(N_i\)</span> the overall weight will be small, favoring <span class="math inline">\(\hat\beta\)</span> and if <span class="math inline">\(N_i\)</span> is large, the overall weight will be large, favoring <span class="math inline">\(\hat\beta^{OLS}_i\)</span>. Here’s a plot of the weight as a function of <span class="math inline">\(N_i\)</span></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="v5-conditional-modes-vs-means.html#cb19-1"></a>Ni.plot =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">50</span></span>
<span id="cb19-2"><a href="v5-conditional-modes-vs-means.html#cb19-2"></a>Wi.plot =<span class="st"> </span>vcov.vals[<span class="dv">1</span>,<span class="dv">4</span>]<span class="op">/</span>(vcov.vals[<span class="dv">1</span>,<span class="dv">4</span>] <span class="op">+</span><span class="st"> </span>vcov.vals[<span class="dv">2</span>,<span class="dv">4</span>]<span class="op">/</span>Ni.plot)</span>
<span id="cb19-3"><a href="v5-conditional-modes-vs-means.html#cb19-3"></a>datplot =<span class="st"> </span><span class="kw">data.frame</span>(Ni.plot, Wi.plot)</span>
<span id="cb19-4"><a href="v5-conditional-modes-vs-means.html#cb19-4"></a><span class="kw">ggplot</span>(datplot, <span class="kw">aes</span>(<span class="dt">x=</span>Ni.plot, <span class="dt">y =</span>Wi.plot)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">y=</span><span class="kw">expression</span>(W[i]), <span class="dt">x =</span> <span class="kw">expression</span>(N[i]))</span></code></pre></div>
<p><img src="3_video5_win_sub_mns_vs_cond_modes_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Granted things will be more difficult if the model has a slope and an intercept (when G is a matrix) and when between-subject variables are included (<span class="math inline">\(A_i\)</span> will not be the identity), but we will deal with that later.</p>
</div>
<div id="verifying-coef.lmer-is-following-the-equation" class="section level2">
<h2>Verifying coef.lmer is following the equation</h2>
<p>Although it is satisfying to find this equation it is only fully satisfying if that is what lmer is doing when we ask for the conditional modes. The following verifies this for each subject.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="v5-conditional-modes-vs-means.html#cb20-1"></a>Wi =<span class="st"> </span>vcov.vals[<span class="dv">1</span>,<span class="dv">4</span>]<span class="op">/</span>(vcov.vals[<span class="dv">1</span>,<span class="dv">4</span>] <span class="op">+</span><span class="st"> </span>vcov.vals[<span class="dv">2</span>,<span class="dv">4</span>]<span class="op">/</span>n.per.sub) </span>
<span id="cb20-2"><a href="v5-conditional-modes-vs-means.html#cb20-2"></a><span class="co"># See first code chunk for n.per.sub</span></span>
<span id="cb20-3"><a href="v5-conditional-modes-vs-means.html#cb20-3"></a>cond.mode.est =<span class="st"> </span>Wi<span class="op">*</span>stage1.est <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>Wi)<span class="op">*</span>beta.hat</span>
<span id="cb20-4"><a href="v5-conditional-modes-vs-means.html#cb20-4"></a></span>
<span id="cb20-5"><a href="v5-conditional-modes-vs-means.html#cb20-5"></a><span class="co"># Stack my estimates on top of lmer&#39;s conditional model estimates</span></span>
<span id="cb20-6"><a href="v5-conditional-modes-vs-means.html#cb20-6"></a><span class="kw">rbind</span>(cond.mode.est, mmcm)                     </span></code></pre></div>
<pre><code>##                   [,1]     [,2]     [,3]    [,4]     [,5]     [,6]     [,7]
## cond.mode.est 256.9017 251.9737 247.7054 251.652 250.0628 260.2288 248.4464
## mmcm          256.9017 251.9737 247.7054 251.652 250.0628 260.2288 248.4464
##                   [,8]     [,9]    [,10]
## cond.mode.est 256.1146 261.2941 254.4678
## mmcm          256.1146 261.2941 254.4678</code></pre>
<p>Satisfying, isn’t it?</p>
<p>What do you think will happen if the within-subject variance is smaller, which is more typical? Will the weights vary as much? No need to re-simulate data, just plug in values for <span class="math inline">\(G\)</span> and <span class="math inline">\(\sigma^2\)</span> and plot the weights as shown below.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="v5-conditional-modes-vs-means.html#cb22-1"></a><span class="co"># Large within-subject variance with respect to between-subject variance (go bold or go home)</span></span>
<span id="cb22-2"><a href="v5-conditional-modes-vs-means.html#cb22-2"></a>Ni.plot =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">50</span>, <span class="dv">5</span>)</span>
<span id="cb22-3"><a href="v5-conditional-modes-vs-means.html#cb22-3"></a></span>
<span id="cb22-4"><a href="v5-conditional-modes-vs-means.html#cb22-4"></a>Wi.plot.large.within =<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">100</span><span class="op">/</span>Ni.plot)</span>
<span id="cb22-5"><a href="v5-conditional-modes-vs-means.html#cb22-5"></a></span>
<span id="cb22-6"><a href="v5-conditional-modes-vs-means.html#cb22-6"></a><span class="co"># Large between-subject variance with respect to within-subject variance</span></span>
<span id="cb22-7"><a href="v5-conditional-modes-vs-means.html#cb22-7"></a>Wi.plot.large.between =<span class="st"> </span><span class="dv">100</span><span class="op">/</span>(<span class="dv">100</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>Ni.plot)</span>
<span id="cb22-8"><a href="v5-conditional-modes-vs-means.html#cb22-8"></a></span>
<span id="cb22-9"><a href="v5-conditional-modes-vs-means.html#cb22-9"></a>Wi.all =<span class="st"> </span><span class="kw">c</span>(Wi.plot.large.within, Wi.plot.large.between)</span>
<span id="cb22-10"><a href="v5-conditional-modes-vs-means.html#cb22-10"></a>Setting =<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Large within-subject&quot;</span>, <span class="st">&quot;Large between-subject&quot;</span>), <span class="dt">each =</span> <span class="kw">length</span>(Ni.plot))</span>
<span id="cb22-11"><a href="v5-conditional-modes-vs-means.html#cb22-11"></a>Ni.all =<span class="st"> </span><span class="kw">c</span>(Ni.plot, Ni.plot)</span>
<span id="cb22-12"><a href="v5-conditional-modes-vs-means.html#cb22-12"></a>datplot2 =<span class="st"> </span><span class="kw">data.frame</span> (Wi.all, Ni.all, Setting)</span>
<span id="cb22-13"><a href="v5-conditional-modes-vs-means.html#cb22-13"></a>cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#E69F00&quot;</span>, <span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>,<span class="st">&quot;#999999&quot;</span>)</span>
<span id="cb22-14"><a href="v5-conditional-modes-vs-means.html#cb22-14"></a></span>
<span id="cb22-15"><a href="v5-conditional-modes-vs-means.html#cb22-15"></a><span class="kw">ggplot</span>(datplot2, <span class="kw">aes</span>(<span class="dt">x=</span>Ni.all, <span class="dt">y =</span>Wi.all, <span class="dt">color =</span> Setting)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="kw">labs</span>(<span class="dt">y=</span><span class="kw">expression</span>(W[i]), <span class="dt">x =</span> <span class="kw">expression</span>(N[i]))<span class="op">+</span><span class="st"> </span><span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>cbPalette)</span></code></pre></div>
<p><img src="3_video5_win_sub_mns_vs_cond_modes_files/figure-html/unnamed-chunk-6-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="summary-2" class="section level2">
<h2>Summary</h2>
<p>The settings in the above were pretty dramatic, but do show the 2SSS approach will likely be very similar to the mixed model result if the between-subject variance is large with respect to the size of the within-subject variance. Further, the weights will vary most across subjects if the sample sizes vary wildly. I would like to highly encourage the reader to run the above code with more settings to see how the weights change.</p>
<p>In the next chapter we will study the group results in more detail, but where the goal isn’t a single group mean, but the difference in means between two groups. Does the 2SSS still work okay is most situations? What if one group has generally less data per subject than the other group? Can that cause false positives or reduced power in the mixed model result? What if we use the conditional modes in an analysis? Does that work okay? All of these questions will be addressed in the next chapter.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="v4-introduction-to-regularization-in-mixed-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="v6-model-strategy-comparison-group-differences.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MixedModelsTutorials.pdf", "MixedModelsTutorials.epub"],
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
